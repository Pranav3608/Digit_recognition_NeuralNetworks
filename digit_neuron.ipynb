{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\prana\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.21)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.30.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Handwritten digit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ea51eb92e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation :\n",
    "y_train contains numbers between 0 and 9 and X_train has digit images of 0 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening the Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train),28*28)\n",
    "X_test_flattened = X_test.reshape(len(X_test),28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  13,\n",
       "        25, 100, 122,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  33,\n",
       "       151, 208, 252, 252, 252, 146,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40,\n",
       "       152, 244, 252, 253, 224, 211, 252, 232,  40,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  15,\n",
       "       152, 239, 252, 252, 252, 216,  31,  37, 252, 252,  60,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  96, 252, 252, 252, 252, 217,  29,   0,  37, 252, 252,  60,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 181, 252, 252, 220, 167,  30,   0,   0,  77, 252,\n",
       "       252,  60,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  26, 128,  58,  22,   0,   0,   0,   0,\n",
       "       100, 252, 252,  60,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 157, 252, 252,  60,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       110, 121, 122, 121, 202, 252, 194,   3,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,\n",
       "        53, 179, 253, 253, 255, 253, 253, 228,  35,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,\n",
       "        54, 227, 252, 243, 228, 170, 242, 252, 252, 231, 117,   6,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         6,  78, 252, 252, 125,  59,   0,  18, 208, 252, 252, 252, 252,\n",
       "        87,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   5, 135, 252, 252, 180,  16,   0,  21, 203, 253, 247, 129,\n",
       "       173, 252, 252, 184,  66,  49,  49,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   3, 136, 252, 241, 106,  17,   0,  53, 200, 252, 216,\n",
       "        65,   0,  14,  72, 163, 241, 252, 252, 223,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 105, 252, 242,  88,  18,  73, 170, 244, 252,\n",
       "       126,  29,   0,   0,   0,   0,   0,  89, 180, 180,  37,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0, 231, 252, 245, 205, 216, 252, 252,\n",
       "       252, 124,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 207, 252, 252, 252, 252,\n",
       "       178, 116,  36,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  13,  93, 143,\n",
       "       121,  23,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 9.9937 - accuracy: 0.8385\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.8737 - accuracy: 0.8793\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.5769 - accuracy: 0.8833\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 5.3940 - accuracy: 0.8862\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 5.4616 - accuracy: 0.8856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea52233b20>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([                                              #Stack of layers in the neural network, every layer would be considered as one element.\n",
    "    keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')  \n",
    "])\n",
    "\n",
    "#Neural Network Compliation\n",
    "model.compile(\n",
    "    optimizer ='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics =['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_flattened, y_train, epochs=5)  #This is where the model training happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation :\n",
    "Accuracy comes to be low. Since values for the images are between 0-255; we need to scale them between 0 & 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), 28*28)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.45490196,\n",
       "       0.49019608, 0.67058824, 1.        , 1.        , 0.58823529,\n",
       "       0.36470588, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.6627451 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.85490196, 0.11764706,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.83529412, 0.55686275, 0.69019608,\n",
       "       0.99215686, 0.99215686, 0.47843137, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.20392157, 0.98039216, 0.99215686, 0.82352941, 0.1254902 ,\n",
       "       0.04705882, 0.        , 0.02352941, 0.80784314, 0.99215686,\n",
       "       0.54901961, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.30196078, 0.98431373,\n",
       "       0.82352941, 0.09803922, 0.        , 0.        , 0.        ,\n",
       "       0.47843137, 0.97254902, 0.99215686, 0.25490196, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.07058824, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.81960784, 0.99215686,\n",
       "       0.99215686, 0.25490196, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.45882353, 0.96862745, 0.99215686, 0.77647059, 0.03921569,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.29803922, 0.96862745, 0.99215686,\n",
       "       0.90588235, 0.24705882, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.50196078, 0.99215686, 0.99215686, 0.56470588, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.69019608, 0.96470588, 0.99215686,\n",
       "       0.62352941, 0.04705882, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.09803922,\n",
       "       0.91764706, 0.99215686, 0.91372549, 0.1372549 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.77647059, 0.99215686, 0.99215686,\n",
       "       0.55294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.30588235,\n",
       "       0.97254902, 0.99215686, 0.74117647, 0.04705882, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0745098 , 0.78431373, 0.99215686, 0.99215686,\n",
       "       0.55294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.5254902 ,\n",
       "       0.99215686, 0.99215686, 0.67843137, 0.04705882, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.97254902, 0.99215686, 0.99215686,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.97254902, 0.99215686, 0.99215686, 0.16862745, 0.07843137,\n",
       "       0.07843137, 0.07843137, 0.07843137, 0.01960784, 0.        ,\n",
       "       0.01960784, 0.07843137, 0.07843137, 0.14509804, 0.58823529,\n",
       "       0.58823529, 0.58823529, 0.57647059, 0.03921569, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97254902, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.65882353, 0.56078431, 0.65098039, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.48235294, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.68235294, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.97647059, 0.96862745,\n",
       "       0.96862745, 0.6627451 , 0.45882353, 0.45882353, 0.22352941,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4627451 , 0.48235294, 0.48235294, 0.48235294, 0.65098039,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.60784314, 0.48235294,\n",
       "       0.48235294, 0.16078431, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaled Values\n",
    "X_test_flattened[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 2ms/step - loss: 0.4686 - accuracy: 0.8760\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3037 - accuracy: 0.9149\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2836 - accuracy: 0.9212\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2728 - accuracy: 0.9234\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2667 - accuracy: 0.9261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea6e7c06d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([                                              #Stack of layers in the neural network, every layer would be considered as one element.\n",
    "    keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')  \n",
    "])\n",
    "\n",
    "#Neural Network Compliation\n",
    "model.compile(\n",
    "    optimizer ='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics =['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_flattened, y_train, epochs=5)  #This is where the model training happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation :\n",
    "Model/Neural Network accuracy imporved from 89% to 92%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Neural Network on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.9244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26965591311454773, 0.9243999719619751]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ea4e871ca0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22/313 [=>............................] - ETA: 0s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.7940383e-02, 3.7363293e-07, 4.0317722e-02, ..., 9.9986821e-01,\n",
       "        8.6444274e-02, 7.2016597e-01],\n",
       "       [4.2706123e-01, 4.6293796e-03, 9.9904299e-01, ..., 1.3389057e-12,\n",
       "        1.6008881e-01, 2.5992386e-09],\n",
       "       [3.8305545e-04, 9.9289769e-01, 6.2728381e-01, ..., 1.3411094e-01,\n",
       "        3.7793308e-01, 5.2755959e-02],\n",
       "       ...,\n",
       "       [3.6649917e-06, 4.6193868e-06, 8.1745011e-04, ..., 1.9841896e-01,\n",
       "        4.3920353e-01, 7.8736037e-01],\n",
       "       [1.5917320e-04, 1.9452191e-04, 1.3430406e-04, ..., 3.5573757e-05,\n",
       "        5.6841546e-01, 9.6736178e-05],\n",
       "       [1.4982378e-02, 2.9356134e-10, 8.8903375e-02, ..., 1.7125487e-08,\n",
       "        2.5007038e-04, 5.9909189e-07]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_flattened)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred[5])    #This returns the max index value from the predictions the model made."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
